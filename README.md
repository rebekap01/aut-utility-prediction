# Automated Evaluation of the Utility of Creative Responses on the Alternate Uses Task

This repository contains the code and data for my Master's thesis project for MSc Behavioural Data Science at the University of Amsterdam. The project aimed to identify the best predictor-model combination for predicting human utility ratings of responses to the Alternate Uses Task. Additionally, it wanted to investigate whether predictors derived from knowledge graphs could help improve this prediction. A number of non-generative machine learning models (naive Bayes, logistic regression, k-nearest neighbors, random forest, XGBoost, LightGBM) were trained on various predictor combinations including number of words (elaboration), (inverse) frequency, semantic distance from AUT object, semantic distance from top 10 uses (either taken as most frequent from the sample or generated by knowledge graph) and semantic distance from related uses (generated by knowledge graph). The best performing model was an XGBoost model containing elaboration, frequency, inverse frequency, similarity to AUT object, USE embeddings, semantic distances to ten common uses, and eight related uses from a generative knowledge graph performing the absolute best. However, knowledge graph predictors did not significantly contribute to the improvement of utility predictions.
